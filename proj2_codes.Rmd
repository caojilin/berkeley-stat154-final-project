---
title: "Proj2_154"
author: "Sizhuo (Cindy) Liu"
date: "4/20/2019"
output: pdf_document
---

1. Data Collection and Exploration

The purpose of the study is to to propose 

```{r}
# Load Image Data & Add Column Names
image1 <- read.table("image_data/image1.txt")
colnames(image1) <- c('y_coordinate', 'x_coordinate', 'expert_label', 'NDAI', 'SD', 'CORR', 'RA_DF', 'RA_CF', 'RA_BF', 'RA_AF', 'RA_AN')
image1$expert_label <- as.factor(image1$expert_label)
image2 <- read.table("image_data/image2.txt")
colnames(image2) <- c('y_coordinate', 'x_coordinate', 'expert_label', 'NDAI', 'SD', 'CORR', 'RA_DF', 'RA_CF', 'RA_BF', 'RA_AF', 'RA_AN')
image2$expert_label <- as.factor(image2$expert_label)
image3 <- read.table("image_data/image3.txt")
colnames(image3) <- c('y_coordinate', 'x_coordinate', 'expert_label', 'NDAI', 'SD', 'CORR', 'RA_DF', 'RA_CF', 'RA_BF', 'RA_AF', 'RA_AN')
image3$expert_label <- as.factor(image3$expert_label)

```

```{r}
# Plot Well-Labeled Map
library(ggplot2)
ggplot(data = image1) + geom_point(aes(x = x_coordinate, y = y_coordinate, color = as.factor(expert_label))) + scale_y_reverse() + scale_color_manual("Expert Labels", labels = c("Not Cloud", "No Label", "Cloud"), values = c("grey", "black", "white"))
ggplot(data = image2) + geom_point(aes(x = x_coordinate, y = y_coordinate, color = as.factor(expert_label))) + scale_y_reverse() + scale_color_manual("Expert Labels", labels = c("Not Cloud", "No Label", "Cloud"), values = c("grey", "black", "white"))
ggplot(data = image3) + geom_point(aes(x = x_coordinate, y = y_coordinate, color = as.factor(expert_label))) + scale_y_reverse() + scale_color_manual("Expert Labels", labels = c("Not Cloud", "No Label", "Cloud"), values = c("grey", "black", "white")) + scale_color_manual("Expert Labels", labels = c("Not Cloud", "No Label", "Cloud"), values = c("grey", "black", "white"))
```

```{r}
# Observe pair-wise relationships between variables ??? Plots different from in the paper
library(scales)
pairs(image1_nozero[,c(4, 5, 6)])
pairs(image2_nozero[,c(4, 5, 6)])


image1_nozero <- image1[-which(image1$expert_label == 0),]
rownames(image1_nozero) <- 1:nrow(image1_nozero)
ggplot(data = image1_nozero) + geom_point(aes(x = CORR, y = rescale(image1_nozero$NDAI, to = c(-0.5, 1)), color = as.factor(expert_label))) + scale_color_manual("Expert Labels", labels = c("Not Cloud", "Cloud"), values = c("blue", "red")) + coord_flip()

image2_nozero <- image2[-which(image2$expert_label == 0),]
rownames(image2_nozero) <- 1:nrow(image2_nozero)
ggplot(data = image2_nozero) + geom_point(aes(x = CORR, y = NDAI, color = as.factor(expert_label))) + scale_color_manual("Expert Labels", labels = c("Not Cloud", "Cloud"), values = c("blue", "red"))

image3_nozero <- image3[-which(image3$expert_label == 0),]
rownames(image3_nozero) <- 1:nrow(image3_nozero)
ggplot(data = image2_nozero) + geom_histogram(aes(x = rescale(image2_nozero$NDAI, to = c(-0.5, 1))))

```

```{r}
# Pairwise Relationships with Expert Label 
ggplot(data = image1_nozero) + geom_boxplot(aes(y = CORR, color = expert_label))
boxplot(image1_nozero$CORR)

ggplot(data = image1_nozero) + geom_histogram(aes(x = CORR, color = expert_label, fill = expert_label, alpha = 0.5))

ggplot(data = image1_nozero) + geom_histogram(aes(x = SD, color = expert_label, fill = expert_label, alpha = 0.5)) + scale_color_manual("Expert Labels", labels = c("Not Cloud", "Cloud"), values = c("blue", "red"))

ggplot(data = image1_nozero) + geom_histogram(aes(x = NDAI, color = expert_label, fill = expert_label, alpha = 0.5)) + scale_color_manual("Expert Labels", labels = c("Not Cloud", "Cloud"), values = c("blue", "red"))
```

2. Preparation

```{r}
# a) Data Split

# Method 1: Split the data from each image individually and then combine 
# Andrew Ng's Recommendation: Training: 60%, Validation: 20%, Testing: 20%
# Image1 Split
image1_nozero$image <- rep(1, nrow(image1_nozero))
all_indices_1 <- 1:nrow(image1_nozero)
test_index_1 <- sample(all_indices, nrow(image1_nozero) * 0.2)
remaining_index_1 <- all_indices_1[-test_index_1]
training_index_1 <- sample(remaining_index_1, length(remaining_index_1) * 0.8)
validation_index_1 <- remaining_index_1[-training_index_1]

train_1 <- image1_nozero[training_index_1,]
validation_1 <- image1_nozero[validation_index_1,]
test_1 <- image1_nozero[test_index_1,]
rownames(image1_nozero)

# Image2 Split
image2_nozero$image <- rep(2, nrow(image2_nozero))
all_indices_2 <- 1:nrow(image2_nozero)
test_index_2 <- sample(all_indices, nrow(image2_nozero) * 0.2)
remaining_index_2 <- all_indices_2[-test_index_2]
training_index_2 <- sample(remaining_index_2, length(remaining_index_2) * 0.8)
validation_index_2 <- remaining_index_2[-training_index_2]

train_2 <- image2_nozero[training_index_2,]
validation_2 <- image2_nozero[validation_index_2,]
test_2 <- image2_nozero[test_index_2,]

# Image3 Split
image3_nozero$image <- rep(3, nrow(image3_nozero))
all_indices_3 <- 1:nrow(image3_nozero)
test_index_3 <- sample(all_indices, nrow(image3_nozero) * 0.3)
remaining_index_3 <- all_indices_3[-test_index_3]
training_index_3 <- sample(remaining_index_3, length(remaining_index_3) * 0.8)
validation_index_3 <- remaining_index_3[-training_index_3]

train_3 <- image3_nozero[training_index_3,]
validation_3 <- image3_nozero[validation_index_3,]
test_3 <- image3_nozero[test_index_3,]

# Combine
train <- rbind(train_1, train_2, train_3)
validation <- rbind(validation_1, validation_2, validation_3)
test <- rbind(test_1, test_2, test_3)
```

```{r}
split_set <- function(data, num) {
    data$image <- rep(num, nrow(data))
    all_indices <- 1:nrow(data)
    test_index <- sample(all_indices, nrow(data) * 0.2)
    remaining_index <- all_indices[-test_index]
    training_index <- sample(remaining_index, length(remaining_index) * 0.8)
    validation_index <- remaining_index[-training_index]
    train <- data[training_index,]
    validation <- data[validation_index,]
    test <- data[test_index,]
    return(list(train = train,validation = validation,test = test))
}

data1 <- split_set(image1_nozero, 1)
data2 <- split_set(image2_nozero, 2)
data3 <- split_set(image3_nozero, 3)
train <- rbind(data1$train, 
               data2$train, data3$train)

validation <- rbind(data1$validation,
                    data2$validation,
                    data3$validation)

test <- rbind(data1$test,
                    data2$test,
                    data3$test)


```



```{r}
# Method 2: Combine the data and then split randomly 
images <- rbind(image1_nozero, image2_nozero, image3_nozero)
index_all <- 1:nrow(images)
test_indices <- sample(index_all, nrow(images) * 0.2)
remaining_indices <- index_all[-test_indices]
training_indices <- sample(remaining_indices, length(remaining_indices) * 0.8)
validation_indices <- remaining_indices[-training_indices]

train_M2 <- images[training_indices,]
validation_M2 <- images[validation_indices,]
test_M2 <- images[test_indices,]
table(train_M2$image) / sum(table(train_M2$image))

```

```{r}
baseline_preds <- -1
# validation accuracy
mean(baseline_preds == validation$expert_label)
# test accuracy
mean(baseline_preds == test$expert_label)
test_index
```


d)
- Method 1 is preferred over Method 2.
- The way method 1 is constructed ensures that in training, validation and test sets, there are equal amounts of data from each image. 
- The table at the end of Method 2, however, suggests that the random selection tends to contain more data from one image than another.




















